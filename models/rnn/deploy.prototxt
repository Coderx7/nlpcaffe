name: "RussellNet"

input: "data"
input_dim: 10
input_dim: 300120
input_dim: 1
input_dim: 1

layers {
  bottom: "data"
  top: "input0"
  top: "target0"
  top: "input1"
  top: "target1"
  top: "input2"
  top: "target2"
  top: "input3"
  top: "target3"
  top: "input4"
  top: "target4"
  top: "input5"
  top: "target5"
  top: "input6"
  top: "target6"
  top: "input7"
  top: "target7"
  top: "input8"
  top: "target8"
  top: "input9"
  top: "target9"
  top: "input10"
  top: "target10"
  top: "input11"
  top: "target11"
  top: "input12"
  top: "target12"
  top: "input13"
  top: "target13"
  top: "input14"
  top: "target14"
  top: "input15"
  top: "target15"
  top: "input16"
  top: "target16"
  top: "input17"
  top: "target17"
  top: "input18"
  top: "target18"
  top: "input19"
  top: "target19"
  top: "input20"
  top: "target20"
  top: "input21"
  top: "target21"
  top: "input22"
  top: "target22"
  top: "input23"
  top: "target23"
  top: "input24"
  top: "target24"
  top: "input25"
  top: "target25"
  top: "input26"
  top: "target26"
  top: "input27"
  top: "target27"
  top: "input28"
  top: "target28"
  top: "input29"
  top: "target29"
  name: "slice"
  type: SLICE
  slice_param {
    slice_dim: 1
    slice_point: 10003
    slice_point: 10004
    slice_point: 20007
    slice_point: 20008
    slice_point: 30011
    slice_point: 30012
    slice_point: 40015
    slice_point: 40016
    slice_point: 50019
    slice_point: 50020
    slice_point: 60023
    slice_point: 60024
    slice_point: 70027
    slice_point: 70028
    slice_point: 80031
    slice_point: 80032
    slice_point: 90035
    slice_point: 90036
    slice_point: 100039
    slice_point: 100040
    slice_point: 110043
    slice_point: 110044
    slice_point: 120047
    slice_point: 120048
    slice_point: 130051
    slice_point: 130052
    slice_point: 140055
    slice_point: 140056
    slice_point: 150059
    slice_point: 150060
    slice_point: 160063
    slice_point: 160064
    slice_point: 170067
    slice_point: 170068
    slice_point: 180071
    slice_point: 180072
    slice_point: 190075
    slice_point: 190076
    slice_point: 200079
    slice_point: 200080
    slice_point: 210083
    slice_point: 210084
    slice_point: 220087
    slice_point: 220088
    slice_point: 230091
    slice_point: 230092
    slice_point: 240095
    slice_point: 240096
    slice_point: 250099
    slice_point: 250100
    slice_point: 260103
    slice_point: 260104
    slice_point: 270107
    slice_point: 270108
    slice_point: 280111
    slice_point: 280112
    slice_point: 290115
    slice_point: 290116
    slice_point: 300119
  }
}
layers {
  top: "dummy_layer"
  name: "dummy_layer"
  type: DUMMY_DATA
  dummy_data_param {
    num: 10
    channels: 250
    height: 1
    width: 1
  }
}
layers {
  top: "dummy_mem_cell"
  name: "dummy_mem_cell"
  type: DUMMY_DATA
  dummy_data_param {
    num: 10
    channels: 250
    height: 1
    width: 1
  }
}
layers {
  bottom: "input0"
  top: "conv0"
  name: "conv0"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv0"
  bottom: "dummy_layer"
  top: "concat_layer0"
  name: "concat_layer0"
  type: CONCAT
}
layers {
  bottom: "concat_layer0"
  bottom: "dummy_mem_cell"
  top: "lstm_layer0"
  top: "lstm_mem_cell0"
  name: "lstm_layer0"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer0"
  top: "inner_product0"
  name: "inner_product0"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product0"
  top: "prob0"
  name: "prob0"
  type: SOFTMAX
}
layers {
  bottom: "input1"
  top: "conv1"
  name: "conv1"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv1"
  bottom: "lstm_layer0"
  top: "concat_layer1"
  name: "concat_layer1"
  type: CONCAT
}
layers {
  bottom: "concat_layer1"
  bottom: "lstm_mem_cell0"
  top: "lstm_layer1"
  top: "lstm_mem_cell1"
  name: "lstm_layer1"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer1"
  top: "inner_product1"
  name: "inner_product1"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product1"
  top: "prob1"
  name: "prob1"
  type: SOFTMAX
}
layers {
  bottom: "input2"
  top: "conv2"
  name: "conv2"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv2"
  bottom: "lstm_layer1"
  top: "concat_layer2"
  name: "concat_layer2"
  type: CONCAT
}
layers {
  bottom: "concat_layer2"
  bottom: "lstm_mem_cell1"
  top: "lstm_layer2"
  top: "lstm_mem_cell2"
  name: "lstm_layer2"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer2"
  top: "inner_product2"
  name: "inner_product2"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product2"
  top: "prob2"
  name: "prob2"
  type: SOFTMAX
}
layers {
  bottom: "input3"
  top: "conv3"
  name: "conv3"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv3"
  bottom: "lstm_layer2"
  top: "concat_layer3"
  name: "concat_layer3"
  type: CONCAT
}
layers {
  bottom: "concat_layer3"
  bottom: "lstm_mem_cell2"
  top: "lstm_layer3"
  top: "lstm_mem_cell3"
  name: "lstm_layer3"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer3"
  top: "inner_product3"
  name: "inner_product3"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product3"
  top: "prob3"
  name: "prob3"
  type: SOFTMAX
}
layers {
  bottom: "input4"
  top: "conv4"
  name: "conv4"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv4"
  bottom: "lstm_layer3"
  top: "concat_layer4"
  name: "concat_layer4"
  type: CONCAT
}
layers {
  bottom: "concat_layer4"
  bottom: "lstm_mem_cell3"
  top: "lstm_layer4"
  top: "lstm_mem_cell4"
  name: "lstm_layer4"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer4"
  top: "inner_product4"
  name: "inner_product4"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product4"
  top: "prob4"
  name: "prob4"
  type: SOFTMAX
}
layers {
  bottom: "input5"
  top: "conv5"
  name: "conv5"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv5"
  bottom: "lstm_layer4"
  top: "concat_layer5"
  name: "concat_layer5"
  type: CONCAT
}
layers {
  bottom: "concat_layer5"
  bottom: "lstm_mem_cell4"
  top: "lstm_layer5"
  top: "lstm_mem_cell5"
  name: "lstm_layer5"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer5"
  top: "inner_product5"
  name: "inner_product5"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product5"
  top: "prob5"
  name: "prob5"
  type: SOFTMAX
}
layers {
  bottom: "input6"
  top: "conv6"
  name: "conv6"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv6"
  bottom: "lstm_layer5"
  top: "concat_layer6"
  name: "concat_layer6"
  type: CONCAT
}
layers {
  bottom: "concat_layer6"
  bottom: "lstm_mem_cell5"
  top: "lstm_layer6"
  top: "lstm_mem_cell6"
  name: "lstm_layer6"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer6"
  top: "inner_product6"
  name: "inner_product6"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product6"
  top: "prob6"
  name: "prob6"
  type: SOFTMAX
}
layers {
  bottom: "input7"
  top: "conv7"
  name: "conv7"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv7"
  bottom: "lstm_layer6"
  top: "concat_layer7"
  name: "concat_layer7"
  type: CONCAT
}
layers {
  bottom: "concat_layer7"
  bottom: "lstm_mem_cell6"
  top: "lstm_layer7"
  top: "lstm_mem_cell7"
  name: "lstm_layer7"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer7"
  top: "inner_product7"
  name: "inner_product7"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product7"
  top: "prob7"
  name: "prob7"
  type: SOFTMAX
}
layers {
  bottom: "input8"
  top: "conv8"
  name: "conv8"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv8"
  bottom: "lstm_layer7"
  top: "concat_layer8"
  name: "concat_layer8"
  type: CONCAT
}
layers {
  bottom: "concat_layer8"
  bottom: "lstm_mem_cell7"
  top: "lstm_layer8"
  top: "lstm_mem_cell8"
  name: "lstm_layer8"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer8"
  top: "inner_product8"
  name: "inner_product8"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product8"
  top: "prob8"
  name: "prob8"
  type: SOFTMAX
}
layers {
  bottom: "input9"
  top: "conv9"
  name: "conv9"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv9"
  bottom: "lstm_layer8"
  top: "concat_layer9"
  name: "concat_layer9"
  type: CONCAT
}
layers {
  bottom: "concat_layer9"
  bottom: "lstm_mem_cell8"
  top: "lstm_layer9"
  top: "lstm_mem_cell9"
  name: "lstm_layer9"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer9"
  top: "inner_product9"
  name: "inner_product9"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product9"
  top: "prob9"
  name: "prob9"
  type: SOFTMAX
}
layers {
  bottom: "input10"
  top: "conv10"
  name: "conv10"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv10"
  bottom: "lstm_layer9"
  top: "concat_layer10"
  name: "concat_layer10"
  type: CONCAT
}
layers {
  bottom: "concat_layer10"
  bottom: "lstm_mem_cell9"
  top: "lstm_layer10"
  top: "lstm_mem_cell10"
  name: "lstm_layer10"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer10"
  top: "inner_product10"
  name: "inner_product10"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product10"
  top: "prob10"
  name: "prob10"
  type: SOFTMAX
}
layers {
  bottom: "input11"
  top: "conv11"
  name: "conv11"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv11"
  bottom: "lstm_layer10"
  top: "concat_layer11"
  name: "concat_layer11"
  type: CONCAT
}
layers {
  bottom: "concat_layer11"
  bottom: "lstm_mem_cell10"
  top: "lstm_layer11"
  top: "lstm_mem_cell11"
  name: "lstm_layer11"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer11"
  top: "inner_product11"
  name: "inner_product11"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product11"
  top: "prob11"
  name: "prob11"
  type: SOFTMAX
}
layers {
  bottom: "input12"
  top: "conv12"
  name: "conv12"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv12"
  bottom: "lstm_layer11"
  top: "concat_layer12"
  name: "concat_layer12"
  type: CONCAT
}
layers {
  bottom: "concat_layer12"
  bottom: "lstm_mem_cell11"
  top: "lstm_layer12"
  top: "lstm_mem_cell12"
  name: "lstm_layer12"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer12"
  top: "inner_product12"
  name: "inner_product12"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product12"
  top: "prob12"
  name: "prob12"
  type: SOFTMAX
}
layers {
  bottom: "input13"
  top: "conv13"
  name: "conv13"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv13"
  bottom: "lstm_layer12"
  top: "concat_layer13"
  name: "concat_layer13"
  type: CONCAT
}
layers {
  bottom: "concat_layer13"
  bottom: "lstm_mem_cell12"
  top: "lstm_layer13"
  top: "lstm_mem_cell13"
  name: "lstm_layer13"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer13"
  top: "inner_product13"
  name: "inner_product13"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product13"
  top: "prob13"
  name: "prob13"
  type: SOFTMAX
}
layers {
  bottom: "input14"
  top: "conv14"
  name: "conv14"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv14"
  bottom: "lstm_layer13"
  top: "concat_layer14"
  name: "concat_layer14"
  type: CONCAT
}
layers {
  bottom: "concat_layer14"
  bottom: "lstm_mem_cell13"
  top: "lstm_layer14"
  top: "lstm_mem_cell14"
  name: "lstm_layer14"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer14"
  top: "inner_product14"
  name: "inner_product14"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product14"
  top: "prob14"
  name: "prob14"
  type: SOFTMAX
}
layers {
  bottom: "input15"
  top: "conv15"
  name: "conv15"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv15"
  bottom: "lstm_layer14"
  top: "concat_layer15"
  name: "concat_layer15"
  type: CONCAT
}
layers {
  bottom: "concat_layer15"
  bottom: "lstm_mem_cell14"
  top: "lstm_layer15"
  top: "lstm_mem_cell15"
  name: "lstm_layer15"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer15"
  top: "inner_product15"
  name: "inner_product15"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product15"
  top: "prob15"
  name: "prob15"
  type: SOFTMAX
}
layers {
  bottom: "input16"
  top: "conv16"
  name: "conv16"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv16"
  bottom: "lstm_layer15"
  top: "concat_layer16"
  name: "concat_layer16"
  type: CONCAT
}
layers {
  bottom: "concat_layer16"
  bottom: "lstm_mem_cell15"
  top: "lstm_layer16"
  top: "lstm_mem_cell16"
  name: "lstm_layer16"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer16"
  top: "inner_product16"
  name: "inner_product16"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product16"
  top: "prob16"
  name: "prob16"
  type: SOFTMAX
}
layers {
  bottom: "input17"
  top: "conv17"
  name: "conv17"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv17"
  bottom: "lstm_layer16"
  top: "concat_layer17"
  name: "concat_layer17"
  type: CONCAT
}
layers {
  bottom: "concat_layer17"
  bottom: "lstm_mem_cell16"
  top: "lstm_layer17"
  top: "lstm_mem_cell17"
  name: "lstm_layer17"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer17"
  top: "inner_product17"
  name: "inner_product17"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product17"
  top: "prob17"
  name: "prob17"
  type: SOFTMAX
}
layers {
  bottom: "input18"
  top: "conv18"
  name: "conv18"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv18"
  bottom: "lstm_layer17"
  top: "concat_layer18"
  name: "concat_layer18"
  type: CONCAT
}
layers {
  bottom: "concat_layer18"
  bottom: "lstm_mem_cell17"
  top: "lstm_layer18"
  top: "lstm_mem_cell18"
  name: "lstm_layer18"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer18"
  top: "inner_product18"
  name: "inner_product18"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product18"
  top: "prob18"
  name: "prob18"
  type: SOFTMAX
}
layers {
  bottom: "input19"
  top: "conv19"
  name: "conv19"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv19"
  bottom: "lstm_layer18"
  top: "concat_layer19"
  name: "concat_layer19"
  type: CONCAT
}
layers {
  bottom: "concat_layer19"
  bottom: "lstm_mem_cell18"
  top: "lstm_layer19"
  top: "lstm_mem_cell19"
  name: "lstm_layer19"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer19"
  top: "inner_product19"
  name: "inner_product19"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product19"
  top: "prob19"
  name: "prob19"
  type: SOFTMAX
}
layers {
  bottom: "input20"
  top: "conv20"
  name: "conv20"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv20"
  bottom: "lstm_layer19"
  top: "concat_layer20"
  name: "concat_layer20"
  type: CONCAT
}
layers {
  bottom: "concat_layer20"
  bottom: "lstm_mem_cell19"
  top: "lstm_layer20"
  top: "lstm_mem_cell20"
  name: "lstm_layer20"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer20"
  top: "inner_product20"
  name: "inner_product20"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product20"
  top: "prob20"
  name: "prob20"
  type: SOFTMAX
}
layers {
  bottom: "input21"
  top: "conv21"
  name: "conv21"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv21"
  bottom: "lstm_layer20"
  top: "concat_layer21"
  name: "concat_layer21"
  type: CONCAT
}
layers {
  bottom: "concat_layer21"
  bottom: "lstm_mem_cell20"
  top: "lstm_layer21"
  top: "lstm_mem_cell21"
  name: "lstm_layer21"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer21"
  top: "inner_product21"
  name: "inner_product21"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product21"
  top: "prob21"
  name: "prob21"
  type: SOFTMAX
}
layers {
  bottom: "input22"
  top: "conv22"
  name: "conv22"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv22"
  bottom: "lstm_layer21"
  top: "concat_layer22"
  name: "concat_layer22"
  type: CONCAT
}
layers {
  bottom: "concat_layer22"
  bottom: "lstm_mem_cell21"
  top: "lstm_layer22"
  top: "lstm_mem_cell22"
  name: "lstm_layer22"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer22"
  top: "inner_product22"
  name: "inner_product22"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product22"
  top: "prob22"
  name: "prob22"
  type: SOFTMAX
}
layers {
  bottom: "input23"
  top: "conv23"
  name: "conv23"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv23"
  bottom: "lstm_layer22"
  top: "concat_layer23"
  name: "concat_layer23"
  type: CONCAT
}
layers {
  bottom: "concat_layer23"
  bottom: "lstm_mem_cell22"
  top: "lstm_layer23"
  top: "lstm_mem_cell23"
  name: "lstm_layer23"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer23"
  top: "inner_product23"
  name: "inner_product23"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product23"
  top: "prob23"
  name: "prob23"
  type: SOFTMAX
}
layers {
  bottom: "input24"
  top: "conv24"
  name: "conv24"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv24"
  bottom: "lstm_layer23"
  top: "concat_layer24"
  name: "concat_layer24"
  type: CONCAT
}
layers {
  bottom: "concat_layer24"
  bottom: "lstm_mem_cell23"
  top: "lstm_layer24"
  top: "lstm_mem_cell24"
  name: "lstm_layer24"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer24"
  top: "inner_product24"
  name: "inner_product24"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product24"
  top: "prob24"
  name: "prob24"
  type: SOFTMAX
}
layers {
  bottom: "input25"
  top: "conv25"
  name: "conv25"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv25"
  bottom: "lstm_layer24"
  top: "concat_layer25"
  name: "concat_layer25"
  type: CONCAT
}
layers {
  bottom: "concat_layer25"
  bottom: "lstm_mem_cell24"
  top: "lstm_layer25"
  top: "lstm_mem_cell25"
  name: "lstm_layer25"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer25"
  top: "inner_product25"
  name: "inner_product25"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product25"
  top: "prob25"
  name: "prob25"
  type: SOFTMAX
}
layers {
  bottom: "input26"
  top: "conv26"
  name: "conv26"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv26"
  bottom: "lstm_layer25"
  top: "concat_layer26"
  name: "concat_layer26"
  type: CONCAT
}
layers {
  bottom: "concat_layer26"
  bottom: "lstm_mem_cell25"
  top: "lstm_layer26"
  top: "lstm_mem_cell26"
  name: "lstm_layer26"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer26"
  top: "inner_product26"
  name: "inner_product26"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product26"
  top: "prob26"
  name: "prob26"
  type: SOFTMAX
}
layers {
  bottom: "input27"
  top: "conv27"
  name: "conv27"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv27"
  bottom: "lstm_layer26"
  top: "concat_layer27"
  name: "concat_layer27"
  type: CONCAT
}
layers {
  bottom: "concat_layer27"
  bottom: "lstm_mem_cell26"
  top: "lstm_layer27"
  top: "lstm_mem_cell27"
  name: "lstm_layer27"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer27"
  top: "inner_product27"
  name: "inner_product27"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product27"
  top: "prob27"
  name: "prob27"
  type: SOFTMAX
}
layers {
  bottom: "input28"
  top: "conv28"
  name: "conv28"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv28"
  bottom: "lstm_layer27"
  top: "concat_layer28"
  name: "concat_layer28"
  type: CONCAT
}
layers {
  bottom: "concat_layer28"
  bottom: "lstm_mem_cell27"
  top: "lstm_layer28"
  top: "lstm_mem_cell28"
  name: "lstm_layer28"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer28"
  top: "inner_product28"
  name: "inner_product28"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product28"
  top: "prob28"
  name: "prob28"
  type: SOFTMAX
}
layers {
  bottom: "input29"
  top: "conv29"
  name: "conv29"
  type: CONVOLUTION
  convolution_param {
    num_output: 200
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
  param: "conv_param"
}
layers {
  bottom: "conv29"
  bottom: "lstm_layer28"
  top: "concat_layer29"
  name: "concat_layer29"
  type: CONCAT
}
layers {
  bottom: "concat_layer29"
  bottom: "lstm_mem_cell28"
  top: "lstm_layer29"
  top: "lstm_mem_cell29"
  name: "lstm_layer29"
  type: LSTM
  lstm_param {
    num_cells: 250
    input_weight_filler {
      type: "xavier"
    }
    input_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_weight_filler {
      type: "xavier"
    }
    input_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    forget_gate_weight_filler {
      type: "xavier"
    }
    forget_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    output_gate_weight_filler {
      type: "xavier"
    }
    output_gate_bias_filler {
      type: "constant"
      value: 0.0
    }
    input_gate_cell_weight_filler: 0
    forget_gate_cell_weight_filler: 0
    output_gate_cell_weight_filler: 0
  }
  param: "lstm_param0"
  param: "lstm_param1"
  param: "lstm_param2"
  param: "lstm_param3"
  param: "lstm_param4"
  param: "lstm_param5"
  param: "lstm_param6"
  param: "lstm_param7"
}
layers {
  bottom: "lstm_layer29"
  top: "inner_product29"
  name: "inner_product29"
  type: INNER_PRODUCT
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  inner_product_param {
    num_output: 10003
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
  param: "inner_product_weight"
  param: "inner_product_bias"
}
layers {
  bottom: "inner_product29"
  top: "prob29"
  name: "prob29"
  type: SOFTMAX
}
layers {
  bottom: "lstm_mem_cell29"
  name: "silence29"
  type: SILENCE
}
